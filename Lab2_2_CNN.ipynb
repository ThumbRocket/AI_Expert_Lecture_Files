{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThumbRocket/AI_Expert_Lecture_Files/blob/main/Lab2_2_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-sbkFbNUAKyK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose,ToTensor\n",
        "\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-mCz91mryvd"
      },
      "source": [
        "#### Connect to local google drive & settings for export/import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x_1Cr9tsrydl",
        "outputId": "32a18f95-c7e7-4188-9749-9d1ad4f513f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘./gdrive/My Drive/MNIST_models/’: File exists\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive')\n",
        "!mkdir ./gdrive/'My Drive'/MNIST_models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2nLnUERGaL_"
      },
      "source": [
        "#### DNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nV9KcFU1FKsR"
      },
      "outputs": [],
      "source": [
        "class MNISTDNN(nn.Module):\n",
        "    def __init__(self,IMG_SIZE=28):\n",
        "        super(MNISTDNN,self).__init__()\n",
        "        self.fc1 = nn.Linear(IMG_SIZE*IMG_SIZE,32)\n",
        "        self.BN1 = torch.nn.BatchNorm1d(32)\n",
        "        self.fc2 = nn.Linear(32,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.softmax(x,dim=-1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNCKxXJwGdN4"
      },
      "source": [
        "#### CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CvofB0pnGfHM"
      },
      "outputs": [],
      "source": [
        "class MNISTCNN(nn.Module):\n",
        "    def __init__(self,IMG_SIZE=28):\n",
        "        super(MNISTCNN,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,8,5,stride=2)\n",
        "        self.BN1 = torch.nn.BatchNorm2d(8)\n",
        "        self.conv2 = nn.Conv2d(8,8,5,stride=2)\n",
        "        self.BN2 = torch.nn.BatchNorm2d(8)\n",
        "        self.conv3 = nn.Conv2d(8,8,3,stride=1)\n",
        "        self.fc = nn.Linear(8*2*2,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = x.view(-1,8*2*2)\n",
        "        x = self.fc(x)\n",
        "        x = torch.softmax(x,dim=-1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zyvh6IKYZcdi"
      },
      "source": [
        "#### Util function for calculating accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7YSzoolPQqIL"
      },
      "outputs": [],
      "source": [
        "def compute_acc(argmax,y):\n",
        "    count = 0\n",
        "    for i in range(len(argmax)):\n",
        "        if argmax[i]==y[i]:\n",
        "            count+=1\n",
        "    return count / len(argmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7KNrp6hGXWI"
      },
      "source": [
        "#### hyperparameters & datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vny-hSnYGOx5"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 28\n",
        "BATCH_SIZE = 256\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHES = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IpnCYlVHBuSW"
      },
      "outputs": [],
      "source": [
        "transforms = Compose([\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = MNIST('/content/gdrive/My Drive/MNIST_models/',train=True,transform=transforms,download=True)\n",
        "testset = MNIST('/content/gdrive/My Drive/MNIST_models/',train=False,transform=transforms,download=True)\n",
        "\n",
        "args = {\n",
        "    'num_workers' : 1,\n",
        "    'batch_size' : BATCH_SIZE,\n",
        "    'shuffle' : True,\n",
        "}\n",
        "\n",
        "train_loader = DataLoader(trainset,**args)\n",
        "test_loader = DataLoader(testset,**args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw9IBUpYZPqb"
      },
      "source": [
        "####Training part(DNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nPSsZM0uGs2z",
        "outputId": "12166624-e521-4a22-cba5-42116a7acce0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters : 25514\n",
            "Epoch 1, Loss(train) : 1.598251092247665\n",
            "Epoch 2, Loss(train) : 1.442443406675011\n",
            "tensor([[1.4936e-03, 1.5286e-03, 4.1107e-04,  ..., 2.9324e-03, 1.4134e-04,\n",
            "         5.6761e-04],\n",
            "        [3.7576e-05, 2.8446e-06, 7.9534e-07,  ..., 2.0448e-04, 3.1563e-04,\n",
            "         9.4248e-04],\n",
            "        [6.3074e-04, 1.9177e-03, 2.2942e-02,  ..., 4.4542e-04, 1.9243e-04,\n",
            "         1.6173e-03],\n",
            "        ...,\n",
            "        [1.2181e-03, 9.7542e-01, 2.9284e-04,  ..., 2.4005e-03, 5.0800e-03,\n",
            "         1.5288e-03],\n",
            "        [3.5470e-04, 9.9029e-01, 1.2189e-03,  ..., 2.5126e-03, 2.2706e-03,\n",
            "         9.0730e-04],\n",
            "        [9.1472e-05, 1.3824e-04, 9.9950e-01,  ..., 7.8784e-05, 1.5901e-05,\n",
            "         3.6044e-07]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Acc(val) : 0.9453125\n",
            "Epoch 3, Loss(train) : 1.4139149473048747\n",
            "Epoch 4, Loss(train) : 1.400166512466967\n",
            "tensor([[9.5460e-06, 2.0420e-06, 5.2733e-05,  ..., 3.5358e-04, 6.2252e-04,\n",
            "         8.6219e-01],\n",
            "        [3.0540e-07, 6.4194e-08, 7.1858e-06,  ..., 1.1308e-08, 6.8330e-08,\n",
            "         6.8135e-08],\n",
            "        [3.3436e-06, 1.0016e-05, 1.0829e-07,  ..., 4.8955e-06, 4.1551e-05,\n",
            "         6.9792e-06],\n",
            "        ...,\n",
            "        [4.5613e-04, 7.1484e-04, 1.8072e-03,  ..., 1.7277e-02, 8.6160e-03,\n",
            "         8.3361e-01],\n",
            "        [7.1262e-06, 1.3980e-04, 3.4620e-03,  ..., 1.3092e-05, 5.9880e-04,\n",
            "         7.2950e-05],\n",
            "        [9.4696e-04, 6.0035e-01, 2.8617e-01,  ..., 3.1817e-02, 7.3447e-02,\n",
            "         5.3004e-05]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Acc(val) : 0.9453125\n",
            "Epoch 5, Loss(train) : 1.391327943187207\n"
          ]
        }
      ],
      "source": [
        "model = MNISTDNN(IMG_SIZE).cuda()\n",
        "\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(\"number of parameters : {}\".format(num_params))\n",
        "\n",
        "optimizer = Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(NUM_EPOCHES):\n",
        "    tot_loss = 0.0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "        y_ = model(x)\n",
        "        loss = loss_fn(y_, y.cuda())\n",
        "        loss.backward()\n",
        "        tot_loss+=loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch {}, Loss(train) : {}\".format(epoch+1,tot_loss/BATCH_SIZE))\n",
        "    if epoch % 2 == 1:\n",
        "        x,y = next(iter(test_loader))\n",
        "        x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "        y_ = model(x)\n",
        "        print(y_)\n",
        "        _, argmax = torch.max(y_,dim=-1)\n",
        "        test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "        print(\"Acc(val) : {}\".format(test_acc))\n",
        "\n",
        "torch.save(model.state_dict(), \"/content/gdrive/My Drive/MNIST_models/DNN.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.parameters())[3].requires_grad"
      ],
      "metadata": {
        "id": "OFVFgMyCP3-f",
        "outputId": "3e3fd4c7-31dc-467c-fd27-670b30f291e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.parameters())[0].size()"
      ],
      "metadata": {
        "id": "wSCkeBPwUUz9",
        "outputId": "bae26c4b-e1cf-4db2-f7d9-6189ded6187d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.prod(list(model.parameters())[0].size())"
      ],
      "metadata": {
        "id": "cVgpiOZRTB12",
        "outputId": "1053ec91-7662-4302-ec90-8dff3ab3fb70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25088"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# self.fc1(x) 784 * 32\n",
        "# F.relu(x) 32\n",
        "# self.BN1(x) 32\n",
        "# self.fc2(x) 10 * 32\n",
        "# torch.softmax(x,dim=-1) 10\n",
        "\n",
        "for i in model.parameters():\n",
        "  print(i.size())"
      ],
      "metadata": {
        "id": "o16a0zkYQcq5",
        "outputId": "3d9c798c-8c93-47de-e20d-e690b20dce0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 784])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "torch.Size([10, 32])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WyC_PAFPMPLw",
        "outputId": "3ad3e841-9421-4a03-de14-cd3f948e5fd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc(test) : 0.953125\n"
          ]
        }
      ],
      "source": [
        "model_test = MNISTDNN(IMG_SIZE).cuda()\n",
        "model_test.load_state_dict(torch.load(\"/content/gdrive/My Drive/MNIST_models/DNN.pt\"))\n",
        "model_test.eval()\n",
        "x,y = next(iter(test_loader))\n",
        "x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "y_ = model_test(x)\n",
        "_, argmax = torch.max(y_,dim=-1)\n",
        "test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "print(\"Acc(test) : {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZlMbw_tZLT-"
      },
      "source": [
        "#### Training part(CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Q_hp82IXWJ4z",
        "outputId": "0a7a55f7-b6d2-49b8-a576-b83218a866e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters : 2762\n",
            "Epoch 1, Loss(train) : 1.6816038410179317\n",
            "Epoch 2, Loss(train) : 1.4096929337829351\n",
            "Acc(test) : 0.97265625\n",
            "Epoch 3, Loss(train) : 1.3866860098205507\n",
            "Epoch 4, Loss(train) : 1.3779380801133811\n",
            "Acc(test) : 0.97265625\n",
            "Epoch 5, Loss(train) : 1.3725390094332397\n"
          ]
        }
      ],
      "source": [
        "model = MNISTCNN(IMG_SIZE).cuda()\n",
        "\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(\"number of parameters : {}\".format(num_params))\n",
        "\n",
        "optimizer = Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(NUM_EPOCHES):\n",
        "    tot_loss = 0.0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        x = x.cuda()\n",
        "        y_ = model(x)\n",
        "        loss = loss_fn(y_, y.cuda())\n",
        "        loss.backward()\n",
        "        tot_loss+=loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch {}, Loss(train) : {}\".format(epoch+1,tot_loss/BATCH_SIZE))\n",
        "    if epoch % 2 == 1:\n",
        "        model.eval()\n",
        "\n",
        "        x,y = next(iter(test_loader))\n",
        "        x = x.cuda()\n",
        "        y_ = model(x)\n",
        "        _, argmax = torch.max(y_,dim=-1)\n",
        "        test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "        print(\"Acc(test) : {}\".format(test_acc))\n",
        "\n",
        "        model.train()\n",
        "\n",
        "torch.save(model.state_dict(), \"/content/gdrive/My Drive/MNIST_models/CNN.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xhN_wmbMR41"
      },
      "outputs": [],
      "source": [
        "model_test = MNISTCNN(IMG_SIZE).cuda()\n",
        "model_test.load_state_dict(torch.load(\"/content/gdrive/My Drive/MNIST_models/CNN.pt\"))\n",
        "model_test.eval()\n",
        "x,y = next(iter(test_loader))\n",
        "x = x.cuda()\n",
        "y_ = model_test(x)\n",
        "_, argmax = torch.max(y_,dim=-1)\n",
        "test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "print(\"Acc(test) : {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSMsL5fKVONu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lab2_2.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}