{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThumbRocket/AI_Expert_Lecture_Files/blob/main/Lab3_1_cGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-sbkFbNUAKyK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose,ToTensor\n",
        "\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXG_qmGXJjwV"
      },
      "source": [
        "### Generative Adversarial Networks\n",
        "#### Generator\n",
        "- Generates fake images\n",
        "- Get labels to generates specific images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmAkE7-J72hU"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self,latent_size):\n",
        "        super(Generator,self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "\n",
        "        self.gen_fc1 = nn.Linear(self.latent_size,128)\n",
        "        self.label_fc = nn.Linear(10,128)\n",
        "        self.gen_fc2 = nn.Linear(256,512)\n",
        "        self.gen_fc3 = nn.Linear(512,784)\n",
        "\n",
        "    def generator(self,label):\n",
        "        batch_size = label.shape[0]\n",
        "        z = torch.randn((batch_size,self.latent_size)) # batch size 만큼 노이즈 만듬\n",
        "        if torch.cuda.is_available():\n",
        "            z = z.cuda()\n",
        "\n",
        "        gen = self.gen_fc1(z) # latent_size -> 128\n",
        "        gen_label = self.label_fc(label) # label -> 128\n",
        "        gen = torch.cat((gen,gen_label),-1) # (batch_size, 128 + 128)로 만듬\n",
        "        gen = torch.relu(gen) # (batch_size, 256), 256 -> 256\n",
        "        gen = self.gen_fc2(gen) # 256 -> 512\n",
        "        gen = torch.relu(gen) # 512 -> 512\n",
        "        gen = self.gen_fc3(gen) # 512 -> 786\n",
        "        img_ = torch.sigmoid(gen).view(-1,1,28,28)\n",
        "        return img_\n",
        "\n",
        "    def forward(self,label):\n",
        "        img = self.generator(label)\n",
        "        return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJWBXpOyJ2oW"
      },
      "source": [
        "#### Discriminator\n",
        "- Find fake images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHG8DS1x2YO1"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator,self).__init__()\n",
        "\n",
        "        self.dis_fc1 = nn.Linear(784,512)\n",
        "        self.dis_fc2 = nn.Linear(512,128)\n",
        "        self.label_fc = nn.Linear(10,128)\n",
        "        self.dis_fc3 = nn.Linear(256,32)\n",
        "        self.dis_fc4 = nn.Linear(32,1)\n",
        "\n",
        "    def discriminator(self,img,label):\n",
        "        batch_size = img.shape[0]\n",
        "        img = img.view(batch_size,-1)\n",
        "\n",
        "        dis = self.dis_fc1(img) # 784 -> 512\n",
        "        dis = torch.relu(dis) # 512 -> 512\n",
        "        dis = self.dis_fc2(dis) # 512 -> 128\n",
        "        dis = torch.relu(dis) # 128 -> 128\n",
        "        dis_label = self.label_fc(label) # 10 -> 128\n",
        "        dis = torch.cat((dis,dis_label),-1) # 128 + 128 -> 256\n",
        "        dis = self.dis_fc3(dis) # 256 -> 32\n",
        "        dis = torch.relu(dis) # 32 -> 32\n",
        "        dis = self.dis_fc4(dis) # 32 -> 1\n",
        "        dis = torch.sigmoid(dis) # -1 ~ 1\n",
        "        return dis\n",
        "\n",
        "    def forward(self,img,label):\n",
        "        criterion = self.discriminator(img,label)\n",
        "        return criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vyo66_AKAXC"
      },
      "source": [
        "#### Util functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuNTK2GI6nEn"
      },
      "outputs": [],
      "source": [
        "def one_hot(x):\n",
        "    res = torch.zeros((x.shape[0],10))\n",
        "    for i in range(x.shape[0]):\n",
        "        res[i,x[i]]=1\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED6guRZjKB6M"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UcXaqkwV6ztF"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 150\n",
        "BATCH_SIZE = 128\n",
        "LATENT_SIZE = 100\n",
        "LEARNING_RATE = 2e-4\n",
        "EPS = 1e-6\n",
        "LEARNING_RATIO = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMYF_p3yKFgU"
      },
      "source": [
        "#### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IpnCYlVHBuSW"
      },
      "outputs": [],
      "source": [
        "transforms = Compose([\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = MNIST('./',train=True,transform=transforms,download=True)\n",
        "testset = MNIST('./',train=False,transform=transforms,download=True)\n",
        "\n",
        "args = {\n",
        "    'num_workers' : 1,\n",
        "    'batch_size' : BATCH_SIZE,\n",
        "    'shuffle' : True,\n",
        "}\n",
        "\n",
        "train_loader = DataLoader(trainset,**args)\n",
        "test_loader = DataLoader(testset,**args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainset)"
      ],
      "metadata": {
        "id": "TgxW8NbXYqFD",
        "outputId": "043430ae-fea2-479e-de2d-5f7dd515260d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset[7][0].shape, trainset[7][0]\n",
        "# image size 28, 28"
      ],
      "metadata": {
        "id": "yDgjkHFdYc-L",
        "outputId": "06559e8e-07d2-47a0-ce2d-e9921b6bfbb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]),\n",
              " tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.1490, 0.1686, 0.4118, 1.0000, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.9922, 0.6824, 0.0235, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.1686, 0.5451, 0.8784, 0.8863, 0.9882, 0.9922, 0.9882,\n",
              "           0.9882, 0.9882, 0.9882, 0.9882, 0.9882, 0.6196, 0.0549, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.6980, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922, 0.9882,\n",
              "           0.9882, 0.9882, 0.9882, 0.9882, 0.9882, 0.9882, 0.2314, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.4275, 0.9882, 0.9882, 0.9020, 0.5176, 0.5216, 0.5176,\n",
              "           0.5176, 0.7412, 0.9882, 0.9882, 0.9882, 0.9882, 0.2314, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.1137, 0.1137, 0.0941, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0549, 0.8863, 0.9882, 0.9882, 0.6745, 0.0275, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.3333, 0.9529, 0.9882, 0.9882, 0.5647, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.3451, 0.7412, 0.9882, 0.9882, 0.9882, 0.0549, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3569, 0.8314,\n",
              "           0.9686, 0.9882, 0.9882, 0.9882, 0.8000, 0.0353, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.1255, 0.4902, 0.7569, 0.7569, 0.7569, 0.9922, 0.9882,\n",
              "           0.9882, 0.9882, 0.9333, 0.4000, 0.1098, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.1765, 0.8706, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922, 0.9882,\n",
              "           0.9882, 0.9882, 0.6941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.1765, 0.8745, 0.9922, 0.9922, 0.9922, 0.9922, 1.0000, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.2902, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.1216, 0.4824, 0.2039, 0.1725, 0.1725, 0.1725, 0.1725,\n",
              "           0.5608, 0.9882, 0.9882, 0.2902, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0588, 0.9882, 0.9882, 0.2902, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.3373, 0.9882, 0.9882, 0.2902, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.2941,\n",
              "           0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3843,\n",
              "           0.9490, 0.9882, 0.9882, 0.2902, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.7176, 0.9882,\n",
              "           0.1137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.3608, 0.9373,\n",
              "           0.9882, 0.9882, 0.9529, 0.2549, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8157, 0.9882, 0.9882,\n",
              "           0.5765, 0.5255, 0.5255, 0.5255, 0.5255, 0.7961, 0.9922, 0.9882,\n",
              "           0.9882, 0.7373, 0.3255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8157, 0.9882, 0.9882,\n",
              "           0.9882, 0.9882, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922, 0.9020,\n",
              "           0.6000, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.6157, 0.9882,\n",
              "           0.9882, 0.9882, 0.9882, 0.9882, 0.8510, 0.8118, 0.5725, 0.1765,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.4039,\n",
              "           0.9216, 0.9882, 0.6745, 0.4039, 0.0941, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJEn6myqKItd"
      },
      "source": [
        "#### Training part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDkcslck6wgQ"
      },
      "outputs": [],
      "source": [
        "gen = Generator(LATENT_SIZE)\n",
        "dis = Discriminator()\n",
        "if torch.cuda.is_available():\n",
        "    gen = gen.cuda()\n",
        "    dis = dis.cuda()\n",
        "\n",
        "gen_parameters = filter(lambda p: p.requires_grad, gen.parameters())\n",
        "num_params = sum([np.prod(p.size()) for p in gen_parameters])\n",
        "print(\"number of parameters(generator) : {}\".format(num_params))\n",
        "dis_parameters = filter(lambda p: p.requires_grad, dis.parameters())\n",
        "num_params = sum([np.prod(p.size()) for p in dis_parameters])\n",
        "print(\"number of parameters(discriminator) : {}\".format(num_params))\n",
        "\n",
        "optimizer_G = Adam(gen.parameters(),lr=LEARNING_RATE)\n",
        "optimizer_D = Adam(dis.parameters(),lr=LEARNING_RATE)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    tot_gen_loss = 0\n",
        "    tot_dis_loss = 0\n",
        "    cnt = 0\n",
        "    for img,label in train_loader:\n",
        "        onehot_label = one_hot(label)\n",
        "        if torch.cuda.is_available():\n",
        "            img = img.cuda()\n",
        "            onehot_label = onehot_label.cuda()\n",
        "\n",
        "        if cnt % LEARNING_RATIO == 0:\n",
        "            optimizer_D.zero_grad()\n",
        "            real = dis(img,onehot_label)\n",
        "            img_ = gen(onehot_label)\n",
        "            fake = dis(img_,onehot_label)\n",
        "            dis_loss = -torch.mean(torch.log(real+EPS)+torch.log(1+EPS-fake))\n",
        "            dis_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        img_ = gen(onehot_label)\n",
        "        fake = dis(img_,onehot_label)\n",
        "        gen_loss = -torch.mean(torch.log(fake+EPS))\n",
        "        gen_loss.backward()\n",
        "        optimizer_G.step()\n",
        "        tot_dis_loss +=dis_loss.item()\n",
        "        tot_gen_loss +=gen_loss.item()\n",
        "        cnt+=1\n",
        "\n",
        "    print(\"epoch {}\\n gen : {:.5f}\\t dis : {:.5f}\".format(epoch+1,tot_gen_loss,tot_dis_loss))\n",
        "    img, label = next(iter(test_loader))\n",
        "    onehot_label = one_hot(label)\n",
        "    if torch.cuda.is_available():\n",
        "        onehot_label = onehot_label.cuda()\n",
        "    img_ = gen(onehot_label)\n",
        "    fig = plt.figure(figsize=(3,3))\n",
        "    fig.add_subplot(1,2,1)\n",
        "    plt.imshow(img[0].squeeze().numpy(),cmap='gray')\n",
        "    plt.axis('off')\n",
        "    img_out = img_[0].squeeze().cpu().detach().numpy()\n",
        "    fig.add_subplot(1,2,2)\n",
        "    plt.imshow(img_out,cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MNIST_cGAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}